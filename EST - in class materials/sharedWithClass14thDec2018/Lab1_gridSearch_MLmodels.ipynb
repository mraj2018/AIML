{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Tumor Detection using KNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider The Wisconsin Breast Cancer Database. \n",
    "\n",
    "Class attribute shows the observation result, whether the patient is suffering from the benign tumor or malignant tumor. \n",
    "\n",
    "Benign tumors do not spread to other parts while the malignant tumor is cancerous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed fields descriptions\n",
    "1. Number of records: 569 \n",
    "2. Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)\n",
    "3. Attribute information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign)\n",
    "3. 3-32: Ten real-valued features are computed for each cell nucleus:\n",
    "4. radius (mean of distances from center to points on the perimeter)\n",
    "5. texture (standard deviation of gray-scale values)\n",
    "6. perimeter\n",
    "7. area\n",
    "8. smoothness (local variation in radius lengths)\n",
    "9. compactness (perimeter^2 / area - 1.0)\n",
    "10. concavity (severity of concave portions of the contour)\n",
    "11. concave points (number of concave portions of the contour)\n",
    "12. symmetry \n",
    "13. fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "### Model different classifier using the Breast Cancer data for predicting whether a patient is suffering from the benign tumor or malignant tumor\n",
    "### Optimize models performance by fine tuning respective models' hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import matplotlib.pyplot as plt   wisc_bc_data\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wisc_bc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                   569 non-null int64\n",
      "diagnosis            569 non-null object\n",
      "radius_mean          569 non-null float64\n",
      "texture_mean         569 non-null float64\n",
      "perimeter_mean       569 non-null float64\n",
      "area_mean            569 non-null float64\n",
      "smoothness_mean      569 non-null float64\n",
      "compactness_mean     569 non-null float64\n",
      "concavity_mean       569 non-null float64\n",
      "points_mean          569 non-null float64\n",
      "symmetry_mean        569 non-null float64\n",
      "dimension_mean       569 non-null float64\n",
      "radius_se            569 non-null float64\n",
      "texture_se           569 non-null float64\n",
      "perimeter_se         569 non-null float64\n",
      "area_se              569 non-null float64\n",
      "smoothness_se        569 non-null float64\n",
      "compactness_se       569 non-null float64\n",
      "concavity_se         569 non-null float64\n",
      "points_se            569 non-null float64\n",
      "symmetry_se          569 non-null float64\n",
      "dimension_se         569 non-null float64\n",
      "radius_worst         569 non-null float64\n",
      "texture_worst        569 non-null float64\n",
      "perimeter_worst      569 non-null float64\n",
      "area_worst           569 non-null float64\n",
      "smoothness_worst     569 non-null float64\n",
      "compactness_worst    569 non-null float64\n",
      "concavity_worst      569 non-null float64\n",
      "points_worst         569 non-null float64\n",
      "symmetry_worst       569 non-null float64\n",
      "dimension_worst      569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>87139402</td>\n",
       "      <td>8910251</td>\n",
       "      <td>905520</td>\n",
       "      <td>868871</td>\n",
       "      <td>9012568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>12.32</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.04</td>\n",
       "      <td>11.28</td>\n",
       "      <td>15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>12.39</td>\n",
       "      <td>18.95</td>\n",
       "      <td>16.83</td>\n",
       "      <td>13.39</td>\n",
       "      <td>13.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>78.85</td>\n",
       "      <td>69.28</td>\n",
       "      <td>70.92</td>\n",
       "      <td>73</td>\n",
       "      <td>97.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>464.1</td>\n",
       "      <td>346.4</td>\n",
       "      <td>373.2</td>\n",
       "      <td>384.8</td>\n",
       "      <td>711.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.07963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.06934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.03393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points_mean</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.02657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension_mean</th>\n",
       "      <td>0.05955</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>0.05544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>0.1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>0.6656</td>\n",
       "      <td>1.197</td>\n",
       "      <td>1.387</td>\n",
       "      <td>1.343</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>1.67</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.342</td>\n",
       "      <td>1.851</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>17.43</td>\n",
       "      <td>27.1</td>\n",
       "      <td>13.54</td>\n",
       "      <td>26.33</td>\n",
       "      <td>17.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.00747</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.01127</td>\n",
       "      <td>0.005012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.03498</td>\n",
       "      <td>0.01485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.01683</td>\n",
       "      <td>0.03354</td>\n",
       "      <td>0.01056</td>\n",
       "      <td>0.02187</td>\n",
       "      <td>0.01551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points_se</th>\n",
       "      <td>0.01241</td>\n",
       "      <td>0.01365</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.01965</td>\n",
       "      <td>0.009155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>0.01924</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.01718</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.01647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension_se</th>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>13.5</td>\n",
       "      <td>11.88</td>\n",
       "      <td>12.41</td>\n",
       "      <td>11.92</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>15.64</td>\n",
       "      <td>22.94</td>\n",
       "      <td>26.44</td>\n",
       "      <td>15.77</td>\n",
       "      <td>15.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>86.97</td>\n",
       "      <td>78.28</td>\n",
       "      <td>79.93</td>\n",
       "      <td>76.53</td>\n",
       "      <td>104.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>549.1</td>\n",
       "      <td>424.8</td>\n",
       "      <td>471.4</td>\n",
       "      <td>434</td>\n",
       "      <td>819.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points_worst</th>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.08178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension_worst</th>\n",
       "      <td>0.06771</td>\n",
       "      <td>0.07587</td>\n",
       "      <td>0.07881</td>\n",
       "      <td>0.06784</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4\n",
       "id                 87139402   8910251    905520    868871   9012568\n",
       "diagnosis                 B         B         B         B         B\n",
       "radius_mean           12.32      10.6     11.04     11.28     15.19\n",
       "texture_mean          12.39     18.95     16.83     13.39     13.21\n",
       "perimeter_mean        78.85     69.28     70.92        73     97.65\n",
       "area_mean             464.1     346.4     373.2     384.8     711.8\n",
       "smoothness_mean      0.1028   0.09688    0.1077    0.1164   0.07963\n",
       "compactness_mean    0.06981    0.1147   0.07804    0.1136   0.06934\n",
       "concavity_mean      0.03987   0.06387   0.03046   0.04635   0.03393\n",
       "points_mean           0.037   0.02642    0.0248   0.04796   0.02657\n",
       "symmetry_mean        0.1959    0.1922    0.1714    0.1771    0.1721\n",
       "dimension_mean      0.05955   0.06491    0.0634   0.06072   0.05544\n",
       "radius_se             0.236    0.4505    0.1967    0.3384    0.1783\n",
       "texture_se           0.6656     1.197     1.387     1.343    0.4125\n",
       "perimeter_se           1.67      3.43     1.342     1.851     1.338\n",
       "area_se               17.43      27.1     13.54     26.33     17.72\n",
       "smoothness_se      0.008045   0.00747  0.005158   0.01127  0.005012\n",
       "compactness_se       0.0118   0.03581  0.009355   0.03498   0.01485\n",
       "concavity_se        0.01683   0.03354   0.01056   0.02187   0.01551\n",
       "points_se           0.01241   0.01365  0.007483   0.01965  0.009155\n",
       "symmetry_se         0.01924   0.03504   0.01718    0.0158   0.01647\n",
       "dimension_se       0.002248  0.003318  0.002198  0.003442  0.001767\n",
       "radius_worst           13.5     11.88     12.41     11.92      16.2\n",
       "texture_worst         15.64     22.94     26.44     15.77     15.73\n",
       "perimeter_worst       86.97     78.28     79.93     76.53     104.5\n",
       "area_worst            549.1     424.8     471.4       434     819.1\n",
       "smoothness_worst     0.1385    0.1213    0.1369    0.1367    0.1126\n",
       "compactness_worst    0.1266    0.2515    0.1482    0.1822    0.1737\n",
       "concavity_worst      0.1242    0.1916    0.1067   0.08669    0.1362\n",
       "points_worst        0.09391   0.07926   0.07431   0.08611   0.08178\n",
       "symmetry_worst       0.2827     0.294    0.2998    0.2102    0.2487\n",
       "dimension_worst     0.06771   0.07587   0.07881   0.06784   0.06766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the \"id\" column\n",
    "data.drop(\"id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the diagnosis variable\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnosis variable is a target variable for the classification\n",
    "#Replace M and B with 1 and 0 respectively\n",
    "data.diagnosis=data.diagnosis.map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(398,)\n",
      "(171, 30)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "#Size of train and test data sets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Hyper Parameters Tuning\n",
    "1. Logistic Regression\n",
    "2. Naive Bayes\n",
    "3. kNearestNeighbors\n",
    "4. Decision Tree\n",
    "5. AdaBoost\n",
    "6. GradientBoosting\n",
    "7. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results without and with hyper parameters\n",
    "resultsDf = pd.DataFrame(index=['Logistic Regression', 'Naive Bayes', 'KNN', 'DecisionTree', \n",
    "                                'AdaBoost', 'GradientBoost', 'RandomForest'])\n",
    "resultsWOHP = []\n",
    "resultsWHP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n",
      "Confusion Metrix:   \n",
      " [[106   6]\n",
      " [  3  56]]\n"
     ]
    }
   ],
   "source": [
    "##### 1. Logistic Regression\n",
    "# Make the instance\n",
    "model = LogisticRegression()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9415204678362573\n",
      "Confusion Metrix:   \n",
      " [[106   7]\n",
      " [  3  55]]\n"
     ]
    }
   ],
   "source": [
    "##### 2. Naive Bayes\n",
    "# Make the instance\n",
    "model = GaussianNB()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9298245614035088\n",
      "Confusion Metrix:   \n",
      " [[104   7]\n",
      " [  5  55]]\n"
     ]
    }
   ],
   "source": [
    "##### 3. kNearestNeighbors\n",
    "# Make the instance\n",
    "model = KNeighborsClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9298245614035088\n",
      "Confusion Metrix:   \n",
      " [[105   8]\n",
      " [  4  54]]\n"
     ]
    }
   ],
   "source": [
    "##### 4. DecisionTree\n",
    "# Make the instance\n",
    "model = DecisionTreeClassifier(random_state=7)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532163742690059\n",
      "Confusion Metrix:   \n",
      " [[106   5]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "##### 5. AdaBoost\n",
    "# Make the instance\n",
    "model = AdaBoostClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n",
      "Confusion Metrix:   \n",
      " [[109   6]\n",
      " [  0  56]]\n"
     ]
    }
   ],
   "source": [
    "##### 6. GradientBoosting\n",
    "# Make the instance\n",
    "model = GradientBoostingClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935672514619883\n",
      "Confusion Metrix:   \n",
      " [[105   7]\n",
      " [  4  55]]\n"
     ]
    }
   ],
   "source": [
    "##### 7. RandomForest\n",
    "# Make the instance\n",
    "model = RandomForestClassifier()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction\n",
    "prediction = model.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))\n",
    "resultsWOHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Hyper Parameters Tuning\n",
    "1. Logistic Regression\n",
    "2. Naive Bayes\n",
    "3. kNearestNeighbors\n",
    "4. Decision Tree\n",
    "5. AdaBoost\n",
    "6. GradientBoosting\n",
    "7. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import GridSearch module\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {}\n",
      "Accuracy: 0.9473684210526315\n",
      "Confusion Metrix:   \n",
      " [[106   6]\n",
      " [  3  56]]\n"
     ]
    }
   ],
   "source": [
    "##### 1. Logistic Regression\n",
    "#Make ML model the instance\n",
    "model= LogisticRegression()\n",
    "#Hyper Parameters Set\n",
    "params = {} ### No hyper parameters for logistic regression\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {}\n",
      "Accuracy: 0.9415204678362573\n",
      "Confusion Metrix:   \n",
      " [[106   7]\n",
      " [  3  55]]\n"
     ]
    }
   ],
   "source": [
    "##### 2. Naive Bayes\n",
    "#Make ML model the instance\n",
    "model = GaussianNB()\n",
    "#Hyper Parameters Set\n",
    "params = {}  ## No hyper parameters for Naive Bayes\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'n_neighbors': 15}\n",
      "Accuracy: 0.935672514619883\n",
      "Confusion Metrix:   \n",
      " [[106   8]\n",
      " [  3  54]]\n"
     ]
    }
   ],
   "source": [
    "##### 3. kNearestNeighbors\n",
    "#Make ML model the instance\n",
    "model = KNeighborsClassifier()\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[5,6,7,8,9,11, 13, 15, 17, 19, 21, 23]}\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "Accuracy: 0.9239766081871345\n",
      "Confusion Metrix:   \n",
      " [[105   9]\n",
      " [  4  53]]\n"
     ]
    }
   ],
   "source": [
    "##### 4. DecisionTree\n",
    "#Import GridSearch module\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Make ML model the instance\n",
    "model= DecisionTreeClassifier(random_state=7)\n",
    "#Hyper Parameters Set\n",
    "params = {'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11]}\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy: 0.9649122807017544\n",
      "Confusion Metrix:   \n",
      " [[108   5]\n",
      " [  1  57]]\n"
     ]
    }
   ],
   "source": [
    "##### 5. AdaBoost\n",
    "#Make ML model the instance\n",
    "model= AdaBoostClassifier(random_state=7)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_estimators':[10,15,20,25,30, 100], \n",
    "          'learning_rate' : [0.01, 0.1, 0.9]}\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'learning_rate': 0.9, 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 25, 'subsample': 0.7}\n",
      "Accuracy: 0.9707602339181286\n",
      "Confusion Metrix:   \n",
      " [[108   4]\n",
      " [  1  58]]\n"
     ]
    }
   ],
   "source": [
    "##### 6. GradientBoosting\n",
    "#Make ML model the instance\n",
    "model= GradientBoostingClassifier(random_state=7)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_estimators':[10, 15, 20, 25, 30, 100],\n",
    "          'max_depth': [3, 5,25], \n",
    "          'min_samples_leaf':[1,3],\n",
    "          'min_samples_split':[2,5,7],\n",
    "          'learning_rate' : [0.01, 0.1,0.9],\n",
    "          'subsample':[0.6,0.7, 1.0], \n",
    "          'max_features':[3, 5, 10, 20]}\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'max_depth': 15, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 20}\n",
      "Accuracy: 0.9649122807017544\n",
      "Confusion Metrix:   \n",
      " [[108   5]\n",
      " [  1  57]]\n"
     ]
    }
   ],
   "source": [
    "##### 7. RandomForest\n",
    "#Make ML model the instance\n",
    "model = RandomForestClassifier(random_state=7)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_estimators':[10,15,20,25,30],\n",
    "          'max_depth': [5, 15, 25, 50], \n",
    "          'min_samples_leaf':[1,2,3],\n",
    "          'min_samples_split':[3,4,5,6,7], \n",
    "          'max_features':[5, 10, 20]}\n",
    "#Make ML model with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "#Train the model\n",
    "model1.fit(X_train, y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)/GreatLearningAIML1/chennai-aug-batch-mraj2018/tree/master/ML\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test)\n",
    "## Evaluation\n",
    "# Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "resultsWHP.append(metrics.accuracy_score(prediction,y_test))\n",
    "# Confusion Metrix \n",
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracyWithOutHPTuning</th>\n",
       "      <th>accuracyWithHPTuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.941520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.935673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.935673</td>\n",
       "      <td>0.923977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.953216</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.970760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.935673</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracyWithOutHPTuning  accuracyWithHPTuning\n",
       "Logistic Regression                 0.947368              0.947368\n",
       "Naive Bayes                         0.941520              0.941520\n",
       "KNN                                 0.929825              0.935673\n",
       "DecisionTree                        0.935673              0.923977\n",
       "AdaBoost                            0.953216              0.964912\n",
       "GradientBoost                       0.964912              0.970760\n",
       "RandomForest                        0.935673              0.964912"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDf['accuracyWithOutHPTuning'] = resultsWOHP\n",
    "resultsDf['accuracyWithHPTuning'] = resultsWHP\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
